# -*- coding: utf-8 -*-
"""Copy of Asteroid Data Visualization & Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q3gopVZj6OG3D6uW2tXJP3n06_bkQ9ck
"""

# https://gitlab.com/mirsakhawathossain/pha-ml/-/raw/master/Dataset/dataset.csv

"""#Import Library"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

'''

# Basic Terminology

When describing an ellipse

a
  is the semi-major axis
b
  is the semi-minor axis
  
e=1−b2/a2−−−−−−−−√
  is the eccenticity of the ellipse
the eccentricity of a circle is 0; that of an ellipse is between 0 and 1
F1
 and F2
 are the foci of the ellipse, located at ±ea
With the simple two-body astronomical description of an orbit about the sun

orbits are typically bounded (elliptical) or unbounded (hyperbolic)
with elipitical orbits, the sun is located at one of the foci
an elliptical orbit's perihelion =a∗(1−e)
 is its point of closest approach to the sun
an elliptical orbit's aphelion =a∗(1+e)
 is its furthest point from the sun
an elliptical orbit's period (in years) is related to its semi-major axis (in AU) as p2=a3
 (Kepler's Third Law)
Note that the concept of eccentricity also applies to parabolas (e=1
) and hyperbolas (e>1
).

'''

'''
If the eccentricity is zero, the curve is a circle; 
if equal to one, a parabola; if less than one, an ellipse; 
and if greater than one, a hyperbola.
'''

"""# Potentially Hazardous Asteroid Prediction - Regression

"""

df = pd.read_csv('https://gitlab.com/mirsakhawathossain/pha-ml/-/raw/master/Dataset/dataset.csv', low_memory=False)

df.columns

dff = df.copy()

dff = dff[['neo', 'pha', 'H',
       'diameter', 'albedo', 'e', 'a', 'q', 'i', 'om', 'w',
       'ma', 'ad', 'n', 'tp', 'tp_cal', 'per', 'per_y', 'class',
       'rms']]

dff

"""

```

Basic Column Definition
SPK-ID: Object primary SPK-ID
Object ID: Object internal database ID
Object fullname: Object full name/designation
pdes: Object primary designation
name: Object IAU name
NEO: Near-Earth Object (NEO) flag
PHA: Potentially Hazardous Asteroid (PHA) flag
H: Absolute magnitude parameter
Diameter: object diameter (from equivalent sphere) km Unit
Albedo: Geometric albedo
Diameter_sigma: 1-sigma uncertainty in object diameter km Unit
Orbit_id: Orbit solution ID
Epoch: Epoch of osculation in modified Julian day form
Equinox: Equinox of reference frame
e: Eccentricity
a: Semi-major axis au Unit
q: perihelion distance au Unit
i: inclination; angle with respect to x-y ecliptic plane
tp: Time of perihelion passage TDB Unit
moid_ld: Earth Minimum Orbit Intersection Distance au Unit


 pha [potentially hazardous object] - target variable
 

```

"""

dff.isnull().sum()



dff[dff['pha'] == 'Y'].isnull().sum()

"""

```
since we are not a domain expert of Asteroid and it potential Hazrds, to clean up the data, we have choose to drop the rest of NaN as we do not know how parameters like, diameter, albedo and diameter_sigma effect the model's outcome
```

"""

dff = dff.dropna()

dff.head()

plt.figure(figsize=(20,10))
plt.title('Count of Potentially Hazardous Asteroid (PHA) flag')
sns.countplot(data=dff, x='pha');

len(dff[dff['pha']=='N'])

len(dff[dff['pha']=='Y'])

len(dff[dff['pha'] == 'Y'])/ len(dff[dff['pha'] == 'N']) * 100

"""# beak"""

dff['pha'] = dff['pha'].map({'Y':1,'N':0})

dff= pd.get_dummies(dff)

dff.columns

"""# Feature Selection RFE"""

from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE

cols = ['H', 'diameter', 'albedo', 'e', 'a', 'q', 'i', 'om', 'w', 'ma',
       'ad', 'n', 'tp', 'tp_cal', 'per', 'per_y', 'rms', 'neo_N', 'neo_Y',
       'class_AMO', 'class_APO', 'class_AST', 'class_ATE', 'class_CEN',
       'class_IMB', 'class_MBA', 'class_MCA', 'class_OMB', 'class_TJN',
       'class_TNO']
X = dff[cols]
y = dff['pha']
# Build a logreg and compute the feature importances
model = LogisticRegression()
# create the RFE model and select 10 attributes
rfe = RFE(model,n_features_to_select=10)
rfe = rfe.fit(X, y)
# summarize the selection of the attributes
print('Selected features: %s' % list(X.columns[rfe.support_]))



dff= dff[['H', 'diameter', 'q', 'i', 'w', 'ma', 'tp', 'tp_cal', 'per', 'per_y']]

dff.info()

"""

```
'AMO' : 'Amor',
        'APO' : 'Apollo',
        'AST' : 'Asteroid (other)',
        'ATE' : 'Aten',
        'CEN' : 'Centaur',
        'HYA' : 'Hyperbolic Asteroid',
        'IEO' : 'Atira',
        'IMB' : 'Inner Main-belt Asteroid',
        'MBA' : 'Main-belt Asteroid',
        'MCA' : 'Mars Crossing Asteroid',
        'OMB' : 'Outer Main-belt Asteroid',
        'TJN' : 'Jupiter Trojan',
        'TNO' : 'TransNeptunian Object'
```

"""

plt.figure(figsize=(30,20))
sns.set(font_scale=2.0)
sns.heatmap(data=round(dff.corr(),2), annot=True)



dff.shape



"""# Modelling

**Splitting the data**
"""

X =  dff[['H', 'diameter', 'q', 'i', 'w', 'ma', 'tp', 'tp_cal', 'per', 'per_y']]
#y = dff['pha']

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""**Scaling the data**"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""**Fitting the data**"""

classifier = LogisticRegression()

classifier.fit(X_train, y_train)

"""**Checking accuracy**"""

from sklearn.metrics import accuracy_score

train_class = classifier.predict(X_train)
print(train_class)

accuracy = accuracy_score(y_train, train_class)
print('Accuracy score: ', accuracy)

## Test data
test_class = classifier.predict(X_test)
print(test_class)

from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score
y_pred = classifier.predict(X_train)

# Overfitting Case
print('---' * 45)
print('Overfitting: \n')
print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))
print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))
print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))
print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))
print('---' * 45)

"""# Logistic Regression with ROC AUC curve metrics """

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score 
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
y_pred_proba = logreg.predict_proba(X_test)[:, 1]

[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)
print('Train/Test split results:')
print(logreg.__class__.__name__+" accuracy is %2.3f" % accuracy_score(y_test, y_pred))
print(logreg.__class__.__name__+" log_loss is %2.3f" % log_loss(y_test, y_pred_proba))
print(logreg.__class__.__name__+" auc is %2.3f" % auc(fpr, tpr))

idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95

plt.figure()
plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')
plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)
plt.ylabel('True Positive Rate (recall)', fontsize=14)
plt.title('Receiver operating characteristic (ROC) curve')
plt.legend(loc="lower right")
plt.show()

print("Using a threshold of %.3f " % thr[idx] + "guarantees a sensitivity of %.3f " % tpr[idx] +  
      "and a specificity of %.3f" % (1-fpr[idx]) + 
      ", i.e. a false positive rate of %.2f%%." % (np.array(fpr[idx])*100))